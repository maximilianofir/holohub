{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "from cuda import cudart\n",
    "from copy import deepcopy\n",
    "import tensorrt as trt\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n",
    "\n",
    "\n",
    "def show_mask(mask, ax):\n",
    "    color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
    "\n",
    "\n",
    "class ImageTensor:\n",
    "    def __init__(self, image):\n",
    "        self.image = image\n",
    "        self.orig_width, self.orig_height = image.size\n",
    "        self.resized_width, self.resized_height = None, None\n",
    "        self.pad_width, self.pad_height = None, None\n",
    "\n",
    "    def size(self):\n",
    "        return self.image.size\n",
    "\n",
    "    def apply_coords(self, coords: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Expects a numpy array of length 2 in the final dimension\n",
    "        \"\"\"\n",
    "        old_h, old_w = self.orig_height, self.orig_width\n",
    "        new_h, new_w = self.resized_height, self.resized_width\n",
    "        coords = deepcopy(coords).astype(float)\n",
    "        coords[..., 0] = coords[..., 0] * (new_w / old_w)\n",
    "        coords[..., 1] = coords[..., 1] * (new_h / old_h)\n",
    "        return coords\n",
    "\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    def __init__(self, long_side_max=1024, mean=None, std=None, image_format=\"RGB\", pad_to_square=True):\n",
    "        self.long_side_max = long_side_max\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.image_format = image_format\n",
    "        self.pad_to_square = pad_to_square\n",
    "        if self.mean is None:\n",
    "            self.mean = np.array([123.675, 116.28, 103.53])\n",
    "        if self.std is None:\n",
    "            self.std = np.array([58.395, 57.12, 57.375])\n",
    "\n",
    "\n",
    "    def resize_image_to_long_side(self, img: ImageTensor):\n",
    "        if self.long_side_max is None:\n",
    "            return img\n",
    "        orig_width, orig_height = img.image.size\n",
    "        if orig_width > orig_height:\n",
    "            img.resized_width = self.long_side_max\n",
    "            img.resized_height = int(self.long_side_max / orig_width * orig_height)\n",
    "        else:\n",
    "            img.resized_height = self.long_side_max\n",
    "            img.resized_width = int(self.long_side_max / orig_height * orig_width)\n",
    "\n",
    "        img.image = img.image.resize((img.resized_width, img.resized_height), Image.Resampling.BILINEAR)\n",
    "        return img\n",
    "\n",
    "    def make_image_rgb(self, image):\n",
    "        if image.image.mode == \"RGB\":\n",
    "            return image\n",
    "        else:\n",
    "            image.image = image.image.convert(\"RGB\")\n",
    "            return image\n",
    "\n",
    "    def pad_image_to_square(self, image):\n",
    "        if isinstance(image, ImageTensor):\n",
    "            image.image = self.pad_image_to_square(image.image)\n",
    "            return image\n",
    "        else:\n",
    "            h, w = image.shape[2:]\n",
    "            max_dim = max(h, w)\n",
    "            pad_h = max_dim - h\n",
    "            pad_w = max_dim - w\n",
    "            image = np.pad(image, ((0,0), (0,0), (0,pad_h), (0,pad_w)), mode=\"constant\", constant_values=0)\n",
    "            return image\n",
    "\n",
    "    def normalize_image(self, image):\n",
    "        if isinstance(image, ImageTensor):\n",
    "            image.image = self.normalize_image(image.image)\n",
    "            return image\n",
    "        else:\n",
    "            image = (image - self.mean) / self.std\n",
    "            return image\n",
    "\n",
    "    def to_tensor(self, image):\n",
    "        if isinstance(image, ImageTensor):\n",
    "            image.image = self.to_tensor(image.image)\n",
    "            return image\n",
    "        else:\n",
    "            image = image.transpose(2,0,1)[None,:,:,:].astype(np.float32)\n",
    "            return image\n",
    "\n",
    "    def from_image_to_input(self, image):\n",
    "        image = self.make_image_rgb(image)\n",
    "        image = self.resize_image_to_long_side(image)\n",
    "        image = self.normalize_image(image)\n",
    "        image = self.to_tensor(image)\n",
    "        # pad to square\n",
    "        if self.pad_to_square:\n",
    "            image = self.pad_image_to_square(image)\n",
    "        return image\n",
    "    \n",
    "def predict_encoder(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    encoder_context.execute_async_v2(bindings, stream.handle, None)\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_shape_dict(batch, points):\n",
    "    embed_dim = 256\n",
    "    embed_size = (64, 64)\n",
    "    mask_input_size = [4 * x for x in embed_size]\n",
    "\n",
    "    return {\n",
    "        \"image_embeddings\": (1, embed_dim, *embed_size),\n",
    "        \"point_coords\": (batch, points, 2),\n",
    "        \"point_labels\": (batch, points),\n",
    "        \"mask_input\": (1, 1, *mask_input_size),\n",
    "        \"has_mask_input\": (1, 1),\n",
    "        \"iou_predictions\": (batch, 4), # up to 4 masks per point\n",
    "        \"low_res_masks\": (batch, 4, *mask_input_size), # up to 4 masks per point\n",
    "    }\n",
    "\n",
    "def get_param_dict(embeddings, image_embedding_size, device, point=(300,300)):\n",
    "    input_point = torch.as_tensor(np.array([point]), device=device, dtype=torch.float32)\n",
    "    input_label = torch.as_tensor(np.array([1]), device=device, dtype=torch.float32)\n",
    "    zero_point = torch.zeros(1, 2, device=device, dtype=torch.float32)\n",
    "    negative_label = torch.as_tensor(np.array([-1]), device=device, dtype=torch.float32)\n",
    "    coord = torch.cat((input_point, zero_point), dim=0)[None, :, :]\n",
    "    label = torch.cat((input_label, negative_label), dim=0)[None, :]\n",
    "    dtype = torch.float32\n",
    "\n",
    "    embeddings = torch.as_tensor(embeddings, dtype=dtype)\n",
    "\n",
    "    mask_input = torch.zeros(1, 1, 4 * image_embedding_size[0], \n",
    "                                4 * image_embedding_size[1], device=device, dtype=dtype)\n",
    "    has_mask_input = torch.zeros((1, 1), dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "    params = {\n",
    "        \"image_embeddings\": embeddings,\n",
    "        \"point_coords\": coord,\n",
    "        \"point_labels\": label,\n",
    "        \"mask_input\": mask_input,\n",
    "        \"has_mask_input\": has_mask_input,\n",
    "    }\n",
    "    return params\n",
    "\n",
    "numpy_to_torch_dtype_dict = {\n",
    "    bool : torch.bool,\n",
    "    np.uint8 : torch.uint8,\n",
    "    np.int8 : torch.int8,\n",
    "    np.int16 : torch.int16,\n",
    "    np.int32 : torch.int32,\n",
    "    np.int64 : torch.int64,\n",
    "    np.float16 : torch.float16,\n",
    "    np.float32 : torch.float32,\n",
    "    np.float64 : torch.float64,\n",
    "    np.complex64 : torch.complex64,\n",
    "    np.complex128 : torch.complex128\n",
    "}\n",
    "\n",
    "def _allocate_buffers(shape_dict, engine, context):\n",
    "    for idx in range(engine.num_io_tensors):\n",
    "        binding = engine[idx]\n",
    "        print(binding)\n",
    "        # if shape_dict and binding in shape_dict:\n",
    "        #     shape = shape_dict[binding]\n",
    "        #     print(f\"shape from dict: {shape}\")\n",
    "        # else:\n",
    "        shape = engine.get_tensor_shape(binding)\n",
    "        print(f\"shape from engine: {shape}\")\n",
    "\n",
    "        dtype = trt.nptype(engine.get_tensor_dtype(binding))\n",
    "        print(f\"Engine dtype {dtype}\")\n",
    "        if engine.get_tensor_mode(binding) == trt.TensorIOMode.INPUT:\n",
    "            context.set_input_shape( binding, shape)\n",
    "            print(len(shape))\n",
    "        else:\n",
    "            print(\"is output\")\n",
    "        tensor = torch.empty(tuple(shape), dtype=numpy_to_torch_dtype_dict[dtype]).to(device=device)\n",
    "        tensors[binding] = tensor\n",
    "\n",
    "def CUASSERT(cuda_ret):\n",
    "    err = cuda_ret[0]\n",
    "    if err != cudart.cudaError_t.cudaSuccess:\n",
    "         raise RuntimeError(f\"CUDA ERROR: {err}, error code reference: https://nvidia.github.io/cuda-python/module/cudart.html#cuda.cudart.cudaError_t\")\n",
    "    if len(cuda_ret) > 1:\n",
    "        return cuda_ret[1]\n",
    "    return None\n",
    "\n",
    "def infer_engine(stream, tensors, param_dict, context, use_cuda_graph=True, cuda_graph_instance=None):\n",
    "    for name, buf in param_dict.items():\n",
    "        tensors[name].copy_(buf)\n",
    "\n",
    "    for name, tensor in tensors.items():\n",
    "        context.set_tensor_address(name, tensor.data_ptr())\n",
    "\n",
    "    if use_cuda_graph:\n",
    "        if cuda_graph_instance is not None:\n",
    "            CUASSERT(cudart.cudaGraphLaunch(cuda_graph_instance, stream.handle))\n",
    "            CUASSERT(cudart.cudaStreamSynchronize(stream.handle))\n",
    "        else:\n",
    "            # do inference before CUDA graph capture\n",
    "            noerror = context.execute_async_v3(stream.handle)\n",
    "            if not noerror:\n",
    "                raise ValueError(f\"ERROR: inference failed.\")\n",
    "            # capture cuda graph\n",
    "            CUASSERT(cudart.cudaStreamBeginCapture(stream.handle, cudart.cudaStreamCaptureMode.cudaStreamCaptureModeGlobal))\n",
    "            context.execute_async_v3(stream.handle)\n",
    "            graph = CUASSERT(cudart.cudaStreamEndCapture(stream.handle))\n",
    "            cuda_graph_instance = CUASSERT(cudart.cudaGraphInstantiate(graph, 0))\n",
    "    else:\n",
    "        noerror = context.execute_async_v3(stream.handle)\n",
    "        if not noerror:\n",
    "            raise ValueError(f\"ERROR: inference failed.\")\n",
    "        \n",
    "\n",
    "    return tensors\n",
    "\n",
    "def scale_tensor_with_aspect_ratio(tensor, max_size):\n",
    "    # assumes tensor dimension (batch, height, width)\n",
    "    height, width = tensor.shape[-2:]\n",
    "    aspect_ratio = width / height\n",
    "    if width > height:\n",
    "        new_width = max_size\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "    else:\n",
    "        new_height = max_size\n",
    "        new_width = int(new_height * aspect_ratio)\n",
    "    # scale tensor dimes (batch, height, width)\n",
    "    scaled_tensor_shape = (new_height, new_width)\n",
    "    scaled_tensor = torch.nn.functional.interpolate(tensor, size=scaled_tensor_shape, mode='bilinear', align_corners=False)\n",
    "    return scaled_tensor\n",
    "\n",
    "def undo_pad_on_tensor(tensor, original_shape):\n",
    "    n_dims = tensor.dim()\n",
    "    width, height = original_shape[:2]\n",
    "    # unpad the tensor\n",
    "    if n_dims == 4:\n",
    "        unpadded_tensor = tensor[:, :, :height, :width]\n",
    "    elif n_dims == 3:\n",
    "        unpadded_tensor = tensor[:, :height, :width]\n",
    "    else:\n",
    "        raise ValueError('Invalid tensor dimension')\n",
    "    return unpadded_tensor\n",
    "\n",
    "def visualize_point_and_mask(image, mask=None, point=None, labels=None, slice_idx=3):\n",
    "    mask_slice = slice(slice_idx, slice_idx+1)\n",
    "    mask = mask[:,mask_slice, :, :]\n",
    "    mask = mask > 0\n",
    "    aspect = plt.figaspect(image)\n",
    "    fig, _ = plt.subplots(figsize=(aspect[0]*2, aspect[1]*2))\n",
    "    fig.subplots_adjust(0,0,1,1)\n",
    "    plt.imshow(image)\n",
    "    if mask is not None:\n",
    "        show_mask(mask.cpu().numpy(), plt.gca())\n",
    "    if point:\n",
    "        show_points(point, labels, plt.gca())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load decoder\n",
    "f = open(\"engine_fp32/decoder.engine\", \"rb\")\n",
    "runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))\n",
    "decoder_engine = runtime.deserialize_cuda_engine(f.read())\n",
    "decoder_context = decoder_engine.create_execution_context()\n",
    "\n",
    "# load encoder\n",
    "f = open(\"engine_fp32/encoder.engine\", \"rb\")\n",
    "encoder_engine = runtime.deserialize_cuda_engine(f.read())\n",
    "encoder_context = encoder_engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "# open sample file\n",
    "####################################################################\n",
    "# image_path = R\"/workspace/sam_trt_pipeline/images/apples.jpg\"\n",
    "# image = Image.open(image_path)\n",
    "\n",
    "image_array = np.load(R\"//workspace/sam_trt_pipeline/images/input_0.npy\")\n",
    "# the numpy array has 4 dims, need to squeeze it to 3 dims\n",
    "image_array = np.squeeze(image_array, 0)\n",
    "# then we transpose so that channels are last\n",
    "image_array = np.transpose(image_array, (1, 2, 0))\n",
    "# scale to 0-255 and convert to uint8\n",
    "image_array = (image_array - image_array.min()) / (image_array.max() - image_array.min()) * 255\n",
    "image_array = image_array.astype(np.uint8)\n",
    "image = Image.fromarray(image_array)\n",
    "# image = Image.fromarray(image_array)\n",
    "################################################################\n",
    "original_image_shape = image.size\n",
    "image_numpy = np.array(image)\n",
    "# image collections for plotting and testing\n",
    "image_original = ImageTensor(image)\n",
    "image_object = ImageTensor(image)\n",
    "\n",
    "# image processor object\n",
    "image_preprocessor = ImagePreprocessor()\n",
    "\n",
    "image_rgb = image_preprocessor.make_image_rgb(image_object)\n",
    "numpy_image = np.array(image_rgb.image)\n",
    "input_image = image_preprocessor.from_image_to_input(image_object)\n",
    "input_tensor = input_image.image\n",
    "\n",
    "device = \"cuda\"\n",
    "stream = cuda.Stream()\n",
    "\n",
    "# apply encoder\n",
    "BATCH_SIZE = 1\n",
    "USE_FP16 = False    \n",
    "target_dtype = np.float16 if USE_FP16 else np.float32\n",
    "# need to set input and output precisions to FP16 to fully enable it\n",
    "output = np.empty([BATCH_SIZE, 256, 64, 64], dtype = target_dtype) \n",
    "# allocate device memory for encoder\n",
    "d_input = cuda.mem_alloc(1 * input_tensor.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "pred = predict_encoder(input_tensor)\n",
    "\n",
    "# apply decoder\n",
    "tensors = OrderedDict()\n",
    "point = (100, 300)\n",
    "point_plotting = np.array([point]), np.array([1]),\n",
    "decoder_shape_dict = get_shape_dict(1, 2)\n",
    "decoder_params = get_param_dict(embeddings=pred, image_embedding_size=(64, 64), device=device, point=point)\n",
    "_allocate_buffers(decoder_shape_dict, decoder_engine, decoder_context)\n",
    "outputs = infer_engine(stream, tensors, decoder_params, decoder_context, use_cuda_graph=True)\n",
    "\n",
    "masks = outputs['low_res_masks']\n",
    "scores = outputs['iou_predictions']\n",
    "\n",
    "scaled_tensor = scale_tensor_with_aspect_ratio(masks, np.max(original_image_shape))\n",
    "unpadded_tensor = undo_pad_on_tensor(scaled_tensor, original_image_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_point_and_mask(image_numpy, mask=unpadded_tensor, slice_idx=3, point=point_plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred[0,1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_cpu = masks.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot the four masks in dim 1 \n",
    "fig, axs = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    axs[i].imshow(masks_cpu[0, i, :, :])\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of the low res masks\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "axs.hist(masks_cpu.flatten(), bins=100)\n",
    "axs.set_title(\"Histogram of low res masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
